{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for i in xrange(1, 50):\n",
    "    x.append([0] * i)\n",
    "    y.append(0)\n",
    "    k = random.randint(0, len(x[-1]) - 1)\n",
    "    x.append(list(x[-1]))\n",
    "    x[-1][k] = 1\n",
    "    y.append(1)\n",
    "\n",
    "zipped = zip(x, y)\n",
    "random.shuffle(zipped)\n",
    "x, y = zip(*zipped)\n",
    "n = int(0.9 * len(zipped))\n",
    "\n",
    "train_x, train_y = x[:n], y[:n]\n",
    "test_x, test_y = x[n:], y[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "\n",
    "\n",
    "class EmbeddingLayer(object):\n",
    "    def __init__(self, embedding_init):\n",
    "        self.embedding_matrix = theano.shared(embedding_init())\n",
    "\n",
    "    def get_output_expr(self, input_expr):\n",
    "        return self.embedding_matrix[input_expr]\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return [self.embedding_matrix]\n",
    "\n",
    "\n",
    "class RnnLayer(object):\n",
    "    def __init__(self, w_init, u_init):\n",
    "        self.W = theano.shared(w_init())\n",
    "        self.U = theano.shared(u_init())\n",
    "\n",
    "    def get_output_expr(self, input_sequence):\n",
    "        h0 = T.zeros((self.W.shape[0], ))\n",
    "\n",
    "        h, _ = theano.scan(fn=self.__get_rnn_step_expr,\n",
    "                           sequences=input_sequence,\n",
    "                           outputs_info=[h0])\n",
    "        return h\n",
    "\n",
    "    def __get_rnn_step_expr(self, x_t, h_tm1):\n",
    "        return T.tanh(T.dot(h_tm1, self.W) + T.dot(x_t, self.U))\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return [self.W, self.U]\n",
    "\n",
    "    \n",
    "class LogisticRegresion(object):\n",
    "    def __init__(self, w_init):\n",
    "        self.W = theano.shared(w_init())\n",
    "        \n",
    "    def get_output_expr(self, input_expr):\n",
    "        pre_softmax_expr = T.dot(input_expr, self.W)\n",
    "        return 1 / (1 + T.exp(pre_softmax_expr))\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return [self.W]\n",
    "    \n",
    "\n",
    "def get_sgd_updates(cost, params, lr=0.01):\n",
    "    grads = T.grad(cost=cost, wrt=params)\n",
    "    updates = []\n",
    "    for p, g in zip(params, grads):\n",
    "        updates.append([p, p - lr * g])\n",
    "    return updates    \n",
    "\n",
    "\n",
    "# def get_sgd_updates(cost, params, lr=0.005, momentum=0.9):\n",
    "#     grads = T.grad(cost=cost, wrt=params)\n",
    "#     updates = []\n",
    "#     for p, g in zip(params, grads):\n",
    "#         v = theano.shared(np.zeros_like(p.get_value()))\n",
    "#         new_v = momentum * v - lr * g\n",
    "#         new_p = p + momentum * new_v - lr * g\n",
    "#         updates.append((v, new_v))\n",
    "#         updates.append((p, new_p))\n",
    "#     return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_init():\n",
    "    return np.random.randn(2, 30) * 0.01\n",
    "\n",
    "\n",
    "def w_init():\n",
    "    shape = (50, 50)\n",
    "    a = np.random.normal(0.0, 1.0, shape)\n",
    "    u, _, v = np.linalg.svd(a, full_matrices=False)\n",
    "    q = u if u.shape == shape else v\n",
    "    q = q.reshape(shape)\n",
    "    return q\n",
    "\n",
    "\n",
    "def u_init():\n",
    "    shape = (30, 50)\n",
    "    a = np.random.normal(0.0, 1.0, shape)\n",
    "    u, _, v = np.linalg.svd(a, full_matrices=False)\n",
    "    q = u if u.shape == shape else v\n",
    "    q = q.reshape(shape)\n",
    "    return q\n",
    "\n",
    "\n",
    "def lr_init():\n",
    "    return np.random.randn(50, ) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergii/Desktop/python_venv/local/lib/python2.7/site-packages/theano/scan_module/scan_perform_ext.py:135: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = EmbeddingLayer(embedding_init)\n",
    "rnn_layer = RnnLayer(w_init, u_init)\n",
    "lr_layer = LogisticRegresion(lr_init)\n",
    "\n",
    "x = T.ivector()\n",
    "y = T.iscalar()\n",
    "\n",
    "embedding_expr = embedding_layer.get_output_expr(x)\n",
    "h = rnn_layer.get_output_expr(embedding_expr)\n",
    "py_x = lr_layer.get_output_expr(h[-1])\n",
    "y_pred = py_x > 0.5\n",
    "cost = - y * T.log(py_x) - (1 - y) * T.log(1 - py_x)\n",
    "updates = get_sgd_updates(cost, embedding_layer.get_parameters() + rnn_layer.get_parameters() + lr_layer.get_parameters())\n",
    "train = theano.function(inputs=[x, y], outputs=cost, updates=updates)\n",
    "val = theano.function(inputs=[x, y], outputs=[cost, y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val 0.0605474268038 1.0\n",
      "==========\n",
      "val 0.0607301514348 1.0\n",
      "==========\n",
      "val 0.0609537797866 1.0\n",
      "==========\n",
      "val 0.0611168442723 1.0\n",
      "==========\n",
      "val 0.0611926951309 1.0\n",
      "==========\n",
      "val 0.0612270088319 1.0\n",
      "==========\n",
      "val 0.0612560931742 1.0\n",
      "==========\n",
      "val 0.0612922533002 1.0\n",
      "==========\n",
      "val 0.0613390221153 1.0\n",
      "==========\n",
      "val 0.0613970343825 1.0\n",
      "==========\n",
      "val 0.0614652808901 1.0\n",
      "==========\n",
      "val 0.0615412807371 1.0\n",
      "==========\n",
      "val 0.0616214397336 1.0\n",
      "==========\n",
      "val 0.0617015924685 1.0\n",
      "==========\n",
      "val 0.0617774463227 1.0\n",
      "==========\n",
      "val 0.0618455297614 1.0\n",
      "==========\n",
      "val 0.0619041530068 1.0\n",
      "==========\n",
      "val 0.0619533935026 1.0\n",
      "==========\n",
      "val 0.0619944248665 1.0\n",
      "==========\n",
      "val 0.0620288544065 1.0\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(200):\n",
    "    for x_datum, y_datum in zip(train_x, train_y):\n",
    "        c.append(train(x_datum, y_datum))\n",
    "    if i % 10 == 0:\n",
    "        c = []\n",
    "        acc = []\n",
    "        for x_datum, y_datum in zip(test_x, test_y):\n",
    "            a, b = val(x_datum, y_datum)\n",
    "            c.append(a)\n",
    "            acc.append(b == y_datum)\n",
    "        print 'val', np.mean(c), np.mean(acc)\n",
    "        print '=' * 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
